{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HF_ENDPOINT=https://hf-mirror.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli download --resume-download Geotrend/bert-base-en-zh-cased --local-dir /home/RE/LitTrain/PreModel/Bert-zh-en-cased --local-dir-use-symlinks False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/RE/LitTrain/PreModel/Bert-zh-en-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/RE/LitTrain/PreModel/Bert-zh-en-cased\")\n",
    "model = AutoModel.from_pretrained(\"/home/RE/LitTrain/PreModel/Bert-zh-en-cased\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "relation = ['attributed-to','exists','indicates','related-to','targets','uses','owns','located','discory','happen','mitigates','through','host']\n",
    "entity = ['idt','mlw','at','ta','vul','cof','ass','ioc','cam','tool','time','trans','loc','moti',]\n",
    "def extract(line):\n",
    "    triples = line['triples'].split(',')\n",
    "    stack = []\n",
    "    datalins = []\n",
    "    targets = []\n",
    "    for itm in triples:\n",
    "        \n",
    "        its = itm.split(' ')\n",
    "        dc = {}\n",
    "        sign=0\n",
    "        for it in its:\n",
    "            \n",
    "            if it.lower() in entity:\n",
    "                if sign ==0:\n",
    "                    \n",
    "                    dc['subject'] = ' '.join(stack)\n",
    "                    stack =[]\n",
    "                    dc['subject_type'] = it.upper()\n",
    "                    sign = 1\n",
    "                else:\n",
    "                    dc['object']=' '.join(stack)\n",
    "                    stack = []\n",
    "                    dc['object_type'] = it.upper()\n",
    "                    \n",
    "            elif it.lower() in relation and sign ==1:\n",
    "                dc['relation']=it.lower()\n",
    "                break\n",
    "            else:\n",
    "                stack.append(it)\n",
    "        datalins.append(dc)\n",
    "    targets=set([(dc['subject'],dc['object'],dc['relation']) for dc in datalins])\n",
    "        \n",
    "    return {\"inputs\":line['context'], \"label\":datalins, 'targets':targets}\n",
    "\n",
    "# CTIdataset.map(extract)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['context', 'triples'],\n",
      "    num_rows: 741\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "with open('/home/RE/Dataset/TK.json','r',encoding='utf-8')as f1:\n",
    "    listx = json.load(f1)\n",
    "with open('/home/RE/Dataset/dealed31.json','r',encoding='utf-8')as f1:\n",
    "    listx.extend(json.load(f1))\n",
    "from datasets import Dataset\n",
    "CTIdataset = Dataset.from_list(listx)\n",
    "print(CTIdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 741/741 [00:00<00:00, 2568.03 examples/s]\n"
     ]
    }
   ],
   "source": [
    "targetdataset=CTIdataset.map(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetdataset=targetdataset.remove_columns(['context','triples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'label', 'targets'],\n",
       "    num_rows: 741\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': '研究人员发现LOBSHOT是通过Windows系统的BITS服务进行恶意代码下载和执行的后门程序。BITS服务是一种文件传输技术，常用于Windows更新。LOBSHOT利用这个服务绕过防火墙和杀毒软件，实现隐蔽攻击。研究人员对LOBSHOT的机制和通信协议进行了分析，并提供了检测规则和防护建议。',\n",
       " 'label': [{'object': 'BITS服务',\n",
       "   'object_type': 'TOOL',\n",
       "   'relation': 'uses',\n",
       "   'subject': 'LOBSHOT',\n",
       "   'subject_type': 'MLW'},\n",
       "  {'object': 'BITS服务',\n",
       "   'object_type': 'TOOL',\n",
       "   'relation': 'owns',\n",
       "   'subject': 'Windows系统',\n",
       "   'subject_type': 'ASS'},\n",
       "  {'object': '恶意代码下载和执行',\n",
       "   'object_type': 'AT',\n",
       "   'relation': 'uses',\n",
       "   'subject': 'LOBSHOT',\n",
       "   'subject_type': 'MLW'}],\n",
       " 'targets': [['LOBSHOT', '恶意代码下载和执行', 'uses'],\n",
       "  ['LOBSHOT', 'BITS服务', 'uses'],\n",
       "  ['Windows系统', 'BITS服务', 'owns']]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetdataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt={\"subj_type2id\":{itm.upper():ith for ith,itm in enumerate(entity,start=1)},\"predicate2id\":{itm.lower():ith for ith,itm in enumerate(relation,start=1)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subj_type2id': {'IDT': 1,\n",
       "  'MLW': 2,\n",
       "  'AT': 3,\n",
       "  'TA': 4,\n",
       "  'VUL': 5,\n",
       "  'COF': 6,\n",
       "  'ASS': 7,\n",
       "  'IOC': 8,\n",
       "  'CAM': 9,\n",
       "  'TOOL': 10,\n",
       "  'TIME': 11,\n",
       "  'TRANS': 12,\n",
       "  'LOC': 13,\n",
       "  'MOTI': 14},\n",
       " 'predicate2id': {'attributed-to': 1,\n",
       "  'exists': 2,\n",
       "  'indicates': 3,\n",
       "  'related-to': 4,\n",
       "  'targets': 5,\n",
       "  'uses': 6,\n",
       "  'owns': 7,\n",
       "  'located': 8,\n",
       "  'discory': 9,\n",
       "  'happen': 10,\n",
       "  'mitigates': 11,\n",
       "  'through': 12,\n",
       "  'host': 13}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在本地加载Json数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/cypy/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal, Union\n",
    "import json, codecs\n",
    "from datasets import Dataset, IterableDataset, load_dataset\n",
    "def dataset_loader(path :str,type:Literal['json','arrow'], stream:bool) -> Union[Dataset,IterableDataset]:\n",
    "    if type == 'json':\n",
    "        train = json.load(codecs.open(path,'r',encoding='utf-8'))\n",
    "    elif type == \"arrow\":\n",
    "        pass\n",
    "    else:\n",
    "        raise TypeError\n",
    "    \n",
    "    dataset = Dataset.from_list(train)\n",
    "    if stream:\n",
    "        dataset.to_iterable_dataset()\n",
    "    return dataset\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "dataset = dataset_loader('/home/RE/Dataset/CTI.json',type='json',stream=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output', 'prompt'],\n",
       "    num_rows: 767\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理dataset\n",
    "\n",
    "源格式 {input,[{relationlist}]}\n",
    "\n",
    "\n",
    "{inputs context\n",
    "labels [\n",
    "\n",
    "    subj1:{subj1,objs,rela},\n",
    "    subj2:{subj2,objs,rela},\n",
    "    ...\n",
    "]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 加载分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/RE/LitTrain/PreModel/Bert-zh-en-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List\n",
    "def return_posi(list1:List,list2: List):\n",
    "    '''\n",
    "    return the start position and end position of list2 in the list1\n",
    "    '''\n",
    "    itm = list2[1:-1]\n",
    "    try:\n",
    "        \n",
    "        eco = list1.index(itm[0])\n",
    "    except Exception as e:\n",
    "        print(f\"{list1}\")\n",
    "        print(f\"{itm} is not exist.detail {e}\")\n",
    "        raise e\n",
    "    ovo = list1.index(itm[-1])\n",
    "    if len(itm)==1:\n",
    "        return eco,eco+1\n",
    "    if list1[eco:ovo+1]==itm:\n",
    "        return eco,ovo+1\n",
    "    else:\n",
    "        \n",
    "        fal={\"head\":0,\"rear\":0}# 记录开始和结束下标\n",
    "        for im, j in enumerate(range(eco,len(list1)),start=eco):\n",
    "            if list1[im] == itm[0] and fal['head']==0:\n",
    "                fal['head']=im\n",
    "                \n",
    "                for b,x in enumerate(itm[1:],start=im+1):\n",
    "                    # 如果当前值相同\n",
    "                    if x ==list1[b]:#\n",
    "                        fal['rear']=b\n",
    "                        continue\n",
    "                    else:\n",
    "                        fal['head']=0\n",
    "                        fal['rear']=0 \n",
    "                        break\n",
    "\n",
    "                if x==itm[-1] and fal['head']!=0:\n",
    "                    fal['rear']=b\n",
    "                    \n",
    "    if list1[fal[\"head\"]:fal['rear']+1]==itm:\n",
    "        return fal[\"head\"],fal['rear']+1\n",
    "    else:\n",
    "        print(itm)\n",
    "        raise \"ERROR\"\n",
    "        return 0,0  \n",
    "def Process_to_pickle(oner:Dict, tokenizer,opt)->Dict:\n",
    "    # print(oner)\n",
    "    '''\n",
    "        oner=['inputs','label']--> inputs -subjoutput[] \n",
    "                                                ---subjoutput[0] objoutput[]\n",
    "            listone [subj,obj,relation],[]\n",
    "            \n",
    "    '''\n",
    "\n",
    "    txt=tokenizer.encode(oner[\"inputs\"])\n",
    "    listone=defaultdict(list)\n",
    "\n",
    "    for item in oner[\"label\"]:\n",
    "\n",
    "        em1=tokenizer.encode(item['subject'])\n",
    "        em2=tokenizer.encode(item['object'])\n",
    "        eca_1,out_1 = return_posi(txt,em1)\n",
    "        e1_type_id = opt[\"subj_type2id\"][item['subject_type']]#获取实体1的类型\n",
    "        eca_2,out_2 = return_posi(txt,em2)\n",
    "        o1_type_id = opt[\"subj_type2id\"][item['object_type']]\n",
    "        rela = opt['predicate2id'][item['relation'].lower()]\n",
    "        if not( txt[eca_1:out_1] == em1[1:-1] and em2[1:-1] == txt[eca_2:out_2]):\n",
    "            raise \"errors 提取错误\"\n",
    "            \n",
    "        # print({str((eca_1,out_1+1)):e1_type_id,str((eca_2,out_2+1)):o1_type_id,\"relaid\":rela})\n",
    "        \n",
    "        listone[str((eca_1,out_1))].append({str((eca_1,out_1)):e1_type_id,str((eca_2,out_2)):o1_type_id,\"relaid\":rela})\n",
    "        \n",
    "        '''\n",
    "        combine list\n",
    "        '''\n",
    "    return {\"inputs\":oner['inputs'],\"labels\":json.dumps(listone,ensure_ascii=False)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 741/741 [00:00<00:00, 1759.64 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "cusprocess = partial(Process_to_pickle,tokenizer=tokenizer,opt=opt)\n",
    "\n",
    "REdataset = targetdataset.map(cusprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'label', 'targets', 'labels'],\n",
       "    num_rows: 741\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "REdataset = REdataset.remove_columns(['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'targets', 'labels'],\n",
       "    num_rows: 741\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REdataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 检查REdataset是否有重复标记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th,i in enumerate(REdataset):\n",
    "    labels = json.loads(i['labels'])\n",
    "    # break\n",
    "    for it in list(labels.keys()):\n",
    "        # print(it)\n",
    "        for itm in labels[it]:\n",
    "            if len(itm.keys())<3:\n",
    "                \n",
    "                print(th,':',i['labels'])\n",
    "            # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': '黑客组织“AgainstTheWest”自2021年10月以来攻击了SonarQube、Gitblit和Gogs等平台，窃取了多家国内企事业单位的代码和数据，并在境外黑客论坛上非法售卖。共约150家单位受到影响，涵盖金融、医疗、政府、军事和高校等多个行业。该组织从受害单位窃取了大量信息系统源代码数据，并在境外黑客论坛RaidForums上进行非法售卖。',\n",
       " 'targets': [['AgainstTheWest', 'Gogs', 'targets'],\n",
       "  ['AgainstTheWest', 'SonarQube', 'targets'],\n",
       "  ['AgainstTheWest', 'Gitblit', 'targets']],\n",
       " 'labels': '{\"(6, 11)\": [{\"(6, 11)\": 4, \"(22, 26)\": 1, \"relaid\": 5}, {\"(6, 11)\": 4, \"(27, 31)\": 1, \"relaid\": 5}, {\"(6, 11)\": 4, \"(32, 34)\": 1, \"relaid\": 5}]}'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REdataset[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "REdataset = REdataset.remove_columns(\"targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'labels'],\n",
       "    num_rows: 741\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REdataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存数据集\n",
    "格式\n",
    "\n",
    "    inputs:text\n",
    "    labels:\n",
    "    [\n",
    "        subj1:{subj1,objs,rela},\n",
    "        subj2:{subj2,objs,rela}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 741/741 [00:00<00:00, 135435.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "REdataset.save_to_disk(\"/home/RE/Dataset/pretrained_ds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理到Joint模式\n",
    "\n",
    "    [\n",
    "        1. subject 预测\n",
    "        2. 根据 subject 预测object\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subj_head' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m             o2[\u001b[38;5;28meval\u001b[39m(obj_index)[\u001b[38;5;241m1\u001b[39m]]\u001b[38;5;241m=\u001b[39mobj_rel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelaid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     36\u001b[0m         dictone[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobj\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobj_head\u001b[39m\u001b[38;5;124m\"\u001b[39m:o1,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobj_tail\u001b[39m\u001b[38;5;124m\"\u001b[39m:o2})\n\u001b[0;32m---> 37\u001b[0m         dictone[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubj\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubj_head\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[43msubj_head\u001b[49m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubj_tail\u001b[39m\u001b[38;5;124m\"\u001b[39m:subj_tail})\n\u001b[1;32m     40\u001b[0m         targets\u001b[38;5;241m.\u001b[39mextend([{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m:tokens,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m:mask,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubjs_head\u001b[39m\u001b[38;5;124m\"\u001b[39m:s1,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubjs_tail\u001b[39m\u001b[38;5;124m\"\u001b[39m:s2,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemory_input\u001b[39m\u001b[38;5;124m'\u001b[39m:memory_inputs,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjs_head\u001b[39m\u001b[38;5;124m'\u001b[39m:dictone[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobj\u001b[39m\u001b[38;5;124m'\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobj_head\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs_tail\u001b[39m\u001b[38;5;124m\"\u001b[39m:dictone[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobj\u001b[39m\u001b[38;5;124m'\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobj_tail\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m'\u001b[39m:itm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m'\u001b[39m]}\u001b[38;5;28;01mfor\u001b[39;00m i,_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dictone[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubj\u001b[39m\u001b[38;5;124m'\u001b[39m])])\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(entity)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subj_head' is not defined"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import pandas\n",
    "ds = load_from_disk('/home/RE/Dataset/pretrained_ds')\n",
    "import torch\n",
    "import collections\n",
    "targets=[]\n",
    "entity=0\n",
    "for Ith,itm in enumerate(ds):\n",
    "    dictone ={}\n",
    "    inputs = tokenizer.encode_plus(itm[\"inputs\"],padding=False,truncation=True)\n",
    "    tokens=inputs['input_ids']\n",
    "    \n",
    "    mask=inputs['attention_mask']\n",
    "    subj_type = collections.defaultdict(list)                       #创建空字典，但访问不存在的键只会返回空 list\n",
    "    obj_type = collections.defaultdict(list)\n",
    "    s1, s2 = [0] * len(tokens), [0] * len(tokens)\n",
    "    items=collections.defaultdict(list)                             #   实体1 对应 实体2的字典\n",
    "    itmx=[]\n",
    "    labels = json.loads(itm['labels'])\n",
    "    subject_index = labels.keys()\n",
    "    for sub in subject_index:\n",
    "        entity+=1\n",
    "        dictone['subj']=[]\n",
    "        dictone['obj']=[]\n",
    "        s1[eval(sub)[0]]=labels[sub][0][sub]\n",
    "        s2[eval(sub)[1]]=labels[sub][0][sub]\n",
    "        \n",
    "        o1, o2 = [0]*len(tokens), [0]*len(tokens)\n",
    "        memory_inputs= [0]*len(tokens)\n",
    "        \n",
    "        memory_inputs[eval(sub)[0]:eval(sub)[1]]=[1]*(eval(sub)[1]-eval(sub)[0])\n",
    "        for obj_rel in labels[sub]:\n",
    "            obj_index = list(obj_rel.keys())[1]\n",
    "            o1[eval(obj_index)[0]]=obj_rel['relaid']\n",
    "            o2[eval(obj_index)[1]]=obj_rel['relaid']\n",
    "        dictone['obj'].append({\"obj_head\":o1,\"obj_tail\":o2})\n",
    "        dictone['subj'].append({\"subj_head\":subj_head,\"subj_tail\":subj_tail})\n",
    "        \n",
    "        \n",
    "        targets.extend([{\"inputs\":tokens,\"mask\":mask,\"subjs_head\":s1,\"subjs_tail\":s2,'memory_input':memory_inputs,'objs_head':dictone['obj'][i]['obj_head'],\"objs_tail\":dictone['obj'][i]['obj_tail'],'targets':itm['targets']}for i,_ in enumerate(dictone['subj'])])\n",
    "print(entity)\n",
    "df= pandas.DataFrame(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'targets', 'labels'],\n",
       "    num_rows: 741\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import pandas\n",
    "ds = load_from_disk('/home/RE/Dataset/pretrained_ds')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'mask', 'subjs_head', 'subjs_tail', 'memory_input', 'objs_head', 'objs_tail', 'targets'],\n",
       "    num_rows: 1256\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据普遍长度3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(i) for i in dataset['inputs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change Pretrained Model to add_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/RE/LitTrain/PreModel/Bert-zh-en-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 100, 7946, 2145, 5299, 5302, 100, 100, 100, 5632, 9960, 2399, 8108, 3299, 809, 3341, 3122, 1140, 749, 100, 510, 100, 1469, 100, 5023, 2398, 1378, 8024, 4961, 1357, 749, 1914, 2157, 1744, 1079, 821, 752, 689, 1296, 855, 4638, 807, 4772, 1469, 3144, 2945, 8024, 2400, 1762, 1862, 1912, 7946, 2145, 6389, 1781, 677, 7478, 3791, 1545, 1297, 511, 1066, 5276, 8269, 2157, 1296, 855, 1358, 1168, 2512, 1510, 8024, 3891, 4667, 7032, 6084, 510, 1278, 4545, 510, 3124, 2424, 510, 1092, 752, 1469, 7770, 3413, 5023, 1914, 702, 6121, 689, 511, 6421, 5299, 5302, 794, 1358, 2154, 1296, 855, 4961, 1357, 749, 1920, 7030, 928, 2622, 5143, 5320, 3975, 807, 4772, 3144, 2945, 8024, 2400, 1762, 1862, 1912, 7946, 2145, 6389, 1781, 100, 677, 6822, 6121, 7478, 3791, 1545, 1297, 511, 102]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode('Today黑客组织“AgainstTheWest”自2021年10月以来攻击了SonarQube、Gitblit和Gogs等平台，窃取了多家国内企事业单位的代码和数据，并在境外黑客论坛上非法售卖。共约150家单位受到影响，涵盖金融、医疗、政府、军事和高校等多个行业。该组织从受害单位窃取了大量信息系统源代码数据，并在境外黑客论坛RaidForums上进行非法售卖。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] [UNK] 黑 客 组 织 [UNK] [UNK] [UNK] 自 2021 年 10 月 以 来 攻 击 了 [UNK] 、 [UNK] 和 [UNK] 等 平 台 ， 窃 取 了 多 家 国 内 企 事 业 单 位 的 代 码 和 数 据 ， 并 在 境 外 黑 客 论 坛 上 非 法 售 卖 。 共 约 150 家 单 位 受 到 影 响 ， 涵 盖 金 融 、 医 疗 、 政 府 、 军 事 和 高 校 等 多 个 行 业 。 该 组 织 从 受 害 单 位 窃 取 了 大 量 信 息 系 统 源 代 码 数 据 ， 并 在 境 外 黑 客 论 坛 [UNK] 上 进 行 非 法 售 卖 。 [SEP]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([101, 100, 7946, 2145, 5299, 5302, 100, 100, 100, 5632, 9960, 2399, 8108, 3299, 809, 3341, 3122, 1140, 749, 100, 510, 100, 1469, 100, 5023, 2398, 1378, 8024, 4961, 1357, 749, 1914, 2157, 1744, 1079, 821, 752, 689, 1296, 855, 4638, 807, 4772, 1469, 3144, 2945, 8024, 2400, 1762, 1862, 1912, 7946, 2145, 6389, 1781, 677, 7478, 3791, 1545, 1297, 511, 1066, 5276, 8269, 2157, 1296, 855, 1358, 1168, 2512, 1510, 8024, 3891, 4667, 7032, 6084, 510, 1278, 4545, 510, 3124, 2424, 510, 1092, 752, 1469, 7770, 3413, 5023, 1914, 702, 6121, 689, 511, 6421, 5299, 5302, 794, 1358, 2154, 1296, 855, 4961, 1357, 749, 1920, 7030, 928, 2622, 5143, 5320, 3975, 807, 4772, 3144, 2945, 8024, 2400, 1762, 1862, 1912, 7946, 2145, 6389, 1781, 100, 677, 6822, 6121, 7478, 3791, 1545, 1297, 511, 102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random, sys, collections, codecs\n",
    "from torch.utils.data import Dataset, get_worker_info\n",
    "from datasets import IterableDataset, load_dataset\n",
    "import torch\n",
    "from typing import Union, Dict\n",
    "def process_func(itm, tokenizer, relatype) -> Dict:\n",
    "    '''\n",
    "    example : \n",
    "        context\n",
    "        triplets:List[Dict[str,str]]\n",
    "    '''\n",
    "    \n",
    "    encoding=tokenizer.encode_plus(itm[\"context\"],padding=False,truncation=True,return_tensors=\"pt\")\n",
    "    \n",
    "    tokens=encoding['input_ids']\n",
    "    tokens=torch.squeeze(tokens, dim=0) \n",
    "    # 2. 掩码\n",
    "    mask = encoding['attention_mask']# 数据掩码\n",
    "    mask=torch.squeeze(mask, dim=0)\n",
    "\n",
    "    \n",
    "    # 记录s1,s2为实体下标位置\n",
    "    # s1, s2 = [0] * len(tokens), [0] * len(tokens)\n",
    "    rela=[[[0]*len(tokens)for _ in range(4)]for _ in  range(relatype)]                             #   关系字典\n",
    "    for i,relapair in enumerate(itm['triple']):                     # 遍历该条记录中每个关系对\n",
    "        itmx=list(relapair.keys())   \n",
    "        if len(itmx)==2:\n",
    "            # 记录首实体\n",
    "            rela[relapair['relaid']-1][0][eval(itmx[0])[0]-1]=relapair[itmx[0]]\n",
    "            rela[relapair['relaid']-1][1][eval(itmx[0])[1]-1]=relapair[itmx[0]]\n",
    "            #记录尾实体\n",
    "            rela[relapair['relaid']-1][2][eval(itmx[0])[0]-1]=relapair[itmx[0]]\n",
    "            rela[relapair['relaid']-1][3][eval(itmx[0])[1]-1]=relapair[itmx[0]]\n",
    "            \n",
    "\n",
    "        else:\n",
    "            rela[relapair['relaid']-1][0][eval(itmx[0])[0]-1]=relapair[itmx[0]]\n",
    "            rela[relapair['relaid']-1][1][eval(itmx[0])[1]-1]=relapair[itmx[0]]\n",
    "            rela[relapair['relaid']-1][2][eval(itmx[1])[0]-1]=relapair[itmx[1]]\n",
    "            rela[relapair['relaid']-1][3][eval(itmx[1])[1]-1]=relapair[itmx[1]]\n",
    "    relatensor = torch.tensor(rela)#25，4，len\n",
    "\n",
    "    labelx=collections.defaultdict(list)\n",
    "    for ith ,itm in enumerate(relatensor,start=1):\n",
    "        labelx[f'{ith}']=itm.to_sparse_coo()\n",
    "    return {\"inputs\":tokens,'mask':mask,\"label\":labelx}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataMatching&Padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas, random\n",
    "from functools import partial\n",
    "def seq_pad(seq, id, max_length):\n",
    "    return seq+[id]*(max_length - len(seq))\n",
    "\n",
    "def pad_sequence(elements, pad_id):\n",
    "    batch = defaultdict(list)\n",
    "    max_length = max([len(sample) for sample in elements['inputs']])\n",
    "    print(max_length)\n",
    "    Cus_seq_padding = partial(seq_pad,max_length = max_length)\n",
    "    \n",
    "    for element in elements:\n",
    "        print(element)\n",
    "        batch['inputs'].append(Cus_seq_padding(element['inputs'],id=pad_id))\n",
    "        batch['masks'].append(Cus_seq_padding(element['mask'],id=0))\n",
    "        batch['subjs_head'].append(Cus_seq_padding(element['subjs_head'], id=0))\n",
    "        batch['subjs_tail'].append( Cus_seq_padding(element['subjs_tail'], id=0))\n",
    "        batch['memory_input'].append(Cus_seq_padding(element['memory_input'], id =0))\n",
    "        batch['objs_head'].append(Cus_seq_padding(element['obj_head'], id=0))\n",
    "        batch['objs_tail'].append( Cus_seq_padding(element['obj_tail'],id =0))\n",
    "    \n",
    "    return {\"inputs\":torch.tensor(batch['inputs']),\n",
    "            \"masks\":torch.tensor(batch[\"masks\"]),\n",
    "            \"subjs_head\":torch.tensor(batch['subjs_head']),\n",
    "            \"subjs_tail\":torch.tensor(batch['subjs_tail']),\n",
    "            \"subj_head\":torch.tensor(batch['subj_head']),\n",
    "            \"subj_tail\":torch.tensor(batch['subj_tail']),\n",
    "            \"objs_head\":torch.tensor(batch['objs_head']),\n",
    "            \"objs_tail\":torch.tensor(batch['objs_tail']),\n",
    "            \"targets\":batch['targets']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchs=defaultdict(list)\n",
    "\n",
    "for i in range(10):\n",
    "    length = random.randint(3,10)\n",
    "    batchs['inputs'].append([random.randint(1,5)]*length)\n",
    "    batchs['mask'].append([1]*length)\n",
    "    batchs['subjs_head'].append([1]*length)\n",
    "    batchs['subjs_tail'].append([1]*length)\n",
    "    batchs['subj_head'].append([i]*length)\n",
    "    batchs['subj_tail'].append([i]*length)\n",
    "    batchs['obj_head'].append([i]*length)\n",
    "    batchs['obj_tail'].append([i]*length)\n",
    "pd = pandas.DataFrame(batchs)\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "dataset = Dataset.from_pandas(pd)\n",
    "print(dataset[3])\n",
    "df=pad_sequence(dataset,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(35225, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model# 768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setting\n",
    "### A joint method for Information Extracting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subjlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class SubTypeLayer(nn.Module):\n",
    "    def __init__(self,args):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(args['hidden_size'])\n",
    "        # layer_norm \n",
    "        self.mlphead = nn.Sequential(# 融合berthidden 和cnn 进行头部的判断\n",
    "            nn.Linear(args['hidden_size'],256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,args['num_subj_type'])\n",
    "        )\n",
    "        self.mlpend = nn.Sequential(\n",
    "            nn.Linear(args['hidden_size'],256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,args['num_subj_type'])\n",
    "            )\n",
    "        self.hiddenLinear=nn.Sequential(\n",
    "            nn.Linear(args['hidden_size'],args['hidden_size']),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(args['dropout'])\n",
    "            )\n",
    "        self.embLinear=nn.Sequential(\n",
    "            nn.Linear(args['hidden_size'],768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(args['dropout'])\n",
    "        )\n",
    "        # 取消bert last_hidden_state的mlp层 \n",
    "        self.last_stateLinear=nn.Sequential(\n",
    "            nn.Linear(args['hidden_size'],768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(args['dropout'])\n",
    "        )\n",
    "        \n",
    "    def forward(self,hidden,emb,last_state):\n",
    "        # hidden=self.attention(hidden)\n",
    "        hidden=self.hiddenLinear(hidden)\n",
    "        emb=self.embLinear(emb)# 对emb内容进行考虑# 映射到 模型的隐藏层\n",
    "        last_state=self.last_stateLinear(last_state)\n",
    "        output1=torch.add(torch.add(hidden,emb),last_state)# 在seq_len上进行拼接\n",
    "        output1 = self.layer_norm(output1)\n",
    "\n",
    "        headlogits=self.mlphead(output1)#\n",
    "        endlogits=self.mlpend(output1)\n",
    "        return headlogits,endlogits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "self.attention 可以观察隐藏层之间的状态关系\n",
    "后续需要通过forward进行数据激活\n",
    "Decoder\n",
    "    weight = B,T,T matmul tril(T,T)\n",
    "    tril\n",
    "        [1,0,0,0]  考虑第一个元素\n",
    "        [1,1,0,0]\n",
    "        [1,1,1,0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss():\n",
    "    '''\n",
    "    compute_loss\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1, 2, 3],\n",
      "        [0, 0, 4, 5, 6],\n",
      "        [0, 0, 7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 创建一个3x3的张量作为示例输入\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "\n",
    "# 定义填充的方式，这里示例在四个方向上填充1个单位\n",
    "padding = (2, 0)  # (left, right, top, bottom)\n",
    "\n",
    "# 进行填充操作\n",
    "padded_x = F.pad(x, padding, \"constant\", value=0)  # \"constant\"填充方式，填充值为0\n",
    "\n",
    "print(padded_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv1d, functional\n",
    "subj_model = Conv1d(768,768,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 150, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as functional\n",
    "inputs = tokenizer.encode_plus('Today黑客组织“AgainstTheWest”自2021年10月以来攻击了SonarQube、Gitblit和Gogs等平台，窃取了多家国内企事业单位的代码和数据，并在境外黑客论坛上非法售卖。共约150家单位受到影响，涵盖金融、医疗、政府、军事和高校等多个行业。该组织从受害单位窃取了大量信息系统源代码数据，并在境外黑客论坛RaidForums上进行非法售卖。',return_tensors='pt')\n",
    "logits = model(**inputs)\n",
    "channel_info = logits.last_hidden_state.permute(0,2,1)\n",
    "logits = functional.pad(channel_info,(2,0),'constant',1)\n",
    "# print(logits.last_hidden_state.shape)\n",
    "logits = subj_model(logits).permute(0,2,1)\n",
    "output = functional.max_pool1d(logits, kernel_size=3)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertForPreTraining, BertTokenizer\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "'''\n",
    "Embedding +pos Embedding\n",
    "        BERT\n",
    "------------\n",
    "      Extracter\n",
    "      Subject --> Object\n",
    "      Memory + Residual Link\n",
    "'''\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model_path, **kwargs):\n",
    "        super.__init__()\n",
    "        self.tokenizer = BertTokenizer(model_path)\n",
    "        self.base = BertModel(model_path)\n",
    "        self.extracter = Extracter(**kwargs)\n",
    "        \n",
    "    def forward(self, inputs, memory_inputs = None):\n",
    "        \n",
    "        logits = self.base(inputs, mask)\n",
    "        if memory_inputs is not None:\n",
    "            subj_head_logits, subj_tail_logits, obj_head_logits, obj_tail_logits, _  = self.extracter(logits, memory_inputs)\n",
    "        else:\n",
    "            triples = self.extracter.predict(logits, inputs)\n",
    "            return triples\n",
    "        return subj_head_logits, subj_tail_logits, obj_head_logits, obj_tail_logits\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def forward(self,hidden_states):\n",
    "        return self.net(hidden_states)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim, **kwargs):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(hidden_dim, hidden_dim,bias=False)\n",
    "        self.query = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.value = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        self.soft_max = nn.Softmax()\n",
    "    def forward(self, memory, hidden_states, memory_inputs):\n",
    "        k = self.key(hidden_states)\n",
    "\n",
    "        q = self.query(hidden_states)\n",
    "        wei = q @ k.transpose(-2,-1) * self.hidden_dim**-0.5 # scaling attention\n",
    "        wei = wei.masked_fill(memory !=0,float('-inf'))\n",
    "        soft_wei = self.soft_max(wei) # 归1\n",
    "        v = self.value(hidden_states)\n",
    "        output = soft_wei @ v # B,L,L * B,L,dim =>B,L,dim\n",
    "        return output\n",
    "class Memory(nn.Module):#Memory + LCN\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.self_attention = MultiHeadAttention(hidden_dim,head_nums =1)\n",
    "        \n",
    "        self.ffwd =FeedForward(hidden_dim=hidden_dim)\n",
    "class MemoryUnit(nn.Module):\n",
    "    def __init__(self, kwargs):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, hidden_state, memory_input):\n",
    "        \n",
    "        pass\n",
    "\n",
    "class LCN(nn.Module):\n",
    "    '''\n",
    "    LCN \n",
    "    Joint a range of Hidden_states\n",
    "    '''\n",
    "    def __init__(self, **kwargs):\n",
    "        self.LCNQ = nn.Conv1d(kwargs['hidden_size'], kwargs['hidden_size'] ,kwargs['kernel_size'], stride=1),\n",
    "        self.LCNQn = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=kwargs['kernel_size']),\n",
    "            nn.Dropout(kwargs['dropout']),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.ActiveLysH = nn.Sequential(\n",
    "            nn.Linear(kwargs['hidden_size']/kwargs['kernel_size'],256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,kwargs['output_layer'])\n",
    "        )\n",
    "        self.ActiveLysT = nn.Sequential(\n",
    "            nn.Linear(kwargs['hidden_size']/kwargs['kernel_size'],256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,kwargs['output_layer'])\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        inputs = functional.pad(inputs.permute(0, 2, 1), (2, 0), \"constant\", 0)\n",
    "        LCN_logits = self.LCNQn(self.LCNQ(inputs).permute(0, 2, 1))\n",
    "        headlogits = self.ActiveLysH(LCN_logits)\n",
    "        taillogits = self.ActiveLysT(LCN_logits)\n",
    "        return headlogits, taillogits\n",
    "class Extracter(nn.Module): # --> hidden_states\n",
    "    def __init__(self, **kwargs):\n",
    "        self.subjextra = LCN(**kwargs)\n",
    "        self.objextra = nn.ModuleDict(Memory(**kwargs))\n",
    "    \n",
    "    def forward(self, hidden_states, memory_inputs, subjs_head, subjs_tail, objs_head, objs_tail):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        subj_head_logits, subj_tail_logits = self.subjextra(hidden_states)\n",
    "        obj_head_logits, obj_tail_logits = self.objextra(memory_inputs, hidden_states)\n",
    "        subj_loss = compute_loss(subj_head_logits,subjs_head) + compute_loss(subj_tail_logits, subjs_tail)\n",
    "        obj_loss = compute_loss(obj_head_logits, objs_head) + compute_loss(obj_tail_logits, objs_tail)\n",
    "        loss = subj_loss + obj_loss\n",
    "        return subj_head_logits, subj_tail_logits, obj_head_logits, obj_tail_logits, loss\n",
    "\n",
    "\n",
    "    def predict(self, hidden_states, inputs):\n",
    "        '''\n",
    "        1. 获得主实体logits\n",
    "        2. 区分主实体并获得其memory_inputs\n",
    "        3. 获得每个主实体的关系Obj\n",
    "        4. 返回主实体logits与objlogits\n",
    "        '''\n",
    "        \n",
    "        subj_head_logits, subj_tail_logits = self.subjextra(hidden_states)\n",
    "        triplelist = []\n",
    "        memory_inputs = self.get_subjs(subj_head_logits, subj_tail_logits, inputs)# \n",
    "        for memory_input in memory_inputs:\n",
    "            memoryinputs = torch.stack(torch.tensor(memory_input[0]),torch.tensor(memory_input[1]),dim=0)\n",
    "            obj_head_logits, obj_tail_logits = self.objextra(memoryinputs, hidden_states)\n",
    "            objs_infos = self.get_subjs(obj_head_logits, obj_tail_logits, inputs)#\n",
    "            \n",
    "            for itm in objs_infos:\n",
    "                triplelist.append(self.tokenizer.decode(memory_input[2]),self.tokenizer.decode(itm[2]),itm[3])\n",
    "            \n",
    "        return set(triplelist)\n",
    "    \n",
    "    \n",
    "    def get_subjs(self, startlogit , endlogit, inputs):\n",
    "        def get_entity_indices(s1, s2, entity_type):\n",
    "            start_indices = torch.nonzero(s1 == entity_type).squeeze(-1)\n",
    "            end_indices = torch.nonzero(s2 == entity_type).squeeze(-1)\n",
    "            entity_indices = []\n",
    "            for start_index in start_indices:\n",
    "                matching_end_indices = end_indices[end_indices >= start_index]  \n",
    "                if len(matching_end_indices) > 0:\n",
    "                    end_index = matching_end_indices[0].item()\n",
    "                    entity_indices.append((start_index.item(), end_index))\n",
    "\n",
    "            return entity_indices\n",
    "        s1,s2 = startlogit.argmax(-1), endlogit.argmax(-1)#选择开始与结束位置  (batch,length)\n",
    "        masked_s1 = torch.zeros_like(s1)\n",
    "        masked_s1[mask.bool()] = s1[mask.bool()]\n",
    "        masked_s2 = torch.zeros_like(s2)\n",
    "        masked_s2[mask.bool()] = s2[mask.bool()]\n",
    "        idlist=s1[(s1!=0)&(s1!=101)&(s1!=102)]\n",
    "        subtensor=[]\n",
    "        for value in torch.unique(idlist):\n",
    "            entitylist=get_entity_indices(s1=s1,s2=s2,entity_type=value.item())\n",
    "            for start,end in entitylist:\n",
    "                tensor_start,tensor_tail = torch.zeros(len(inputs)), torch.zeros(len(inputs))\n",
    "                tensor_start[start]=1\n",
    "                tensor_tail[end]=1\n",
    "                value_tensor = inputs[start:end+1]\n",
    "                subtensor.append((tensor_start,tensor_tail,value_tensor,value.item()))\n",
    "        return subtensor\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification,BertForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "def get_scheduler(optimizer, scheduler_type, **kwargs):\n",
    "    if scheduler_type == 'step':\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=kwargs['step_size'], gamma=kwargs['gamma'])\n",
    "    elif scheduler_type == 'exp':\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=kwargs['gamma']) # 不适宜太小\n",
    "    elif scheduler_type == 'linear':\n",
    "        scheduler = lr_scheduler.LinearLR(optimizer,start_factor=kwargs['start_factor'],end_factor=kwargs['end_factor'],total_iters= kwargs['total_iters'])\n",
    "    elif scheduler_type == 'cosine':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=kwargs['T_max'],eta_min=kwargs['eta_min'])\n",
    "    elif scheduler_type == 'reduce':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=kwargs['factor'], patience=kwargs['patience'])\n",
    "    elif scheduler_type ==\"cosineAnneal\":\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer=optimizer,T_max=kwargs['T_max'],eta_min=kwargs['eta_min'])\n",
    "    else:\n",
    "        scheduler = None\n",
    "        print(\"Invalid scheduler type. Please choose from 'step', 'exp', or 'reduce'.\")\n",
    "\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(name, parameters,**kwargs):\n",
    "    if name == 'sgd':\n",
    "        return torch.optim.SGD(parameters, lr=kwargs['lr'])\n",
    "    elif name == 'adam':\n",
    "        return torch.optim.Adam(parameters, lr=kwargs['lr'], betas=(0.9, 0.99), **kwargs) \n",
    "    elif name == 'adamax':\n",
    "        return torch.optim.Adamax(parameters, lr=kwargs['lr'])\n",
    "    elif name == 'adamw':\n",
    "        return torch.optim.AdamW(parameters,lr=kwargs['lr'])\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Unsupported optimizer: {}\".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from transformers import AdamW\n",
    "import time\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "class ReTrainer(object):\n",
    "    def __init__(self,trainingargs, modelargs,globalargs,trainloader,valloader,tokenizer,id2predicate,model):\n",
    "        # 初始化\n",
    "        # 学习率调度器初始化\n",
    "        # optimizer初始化\n",
    "        # dataloader\n",
    "        # model\n",
    "        # self.logger、helper\n",
    "        # wandb.init(project=\"RETask\",name=globalargs['wandbname'])\n",
    "        self.device=trainingargs['device']\n",
    "        self.trainloader=trainloader\n",
    "        self.valloader = valloader\n",
    "        self.model=model.to(self.device)\n",
    "        self.trainingargs=trainingargs\n",
    "        self.optimizer = get_optimizer(trainingargs['optim'],self.model.parameters(),**trainingargs)\n",
    "        self.scheduler = get_scheduler(self.optimizer,trainingargs['scheduler'],**trainingargs)        \n",
    "        self.globalargs = globalargs\n",
    "        # globalargs config存放位置、model_save_dir:+id模型参数存放位置 \\ +log表示模型日志文件存放位置\n",
    "        if trainingargs['from_ckpt']:# 是否在检查点恢复训练\n",
    "            try:\n",
    "                self.load_model(trainingargs['from_ckpt'])\n",
    "            except:\n",
    "                FileNotFoundError\n",
    "        self.num_epochs = trainingargs['num_epochs']\n",
    "        self.tokenizer = tokenizer\n",
    "        self.id2predicate = id2predicate\n",
    "        self.checkpoints = globalargs['checkpoints'] if globalargs.get('checkpoints') else {}\n",
    "        self.total_save_limit = trainingargs['total_save_limit']\n",
    "        # self.optimizer=self.optimizer.to(self.device)\n",
    "        pass\n",
    "    # 损失函数计算方法\n",
    "    def compute_loss(self,y_true,y_pred,mask):\n",
    "        y_true=y_true.long()\n",
    "        loss = F.cross_entropy(y_pred.reshape(-1,y_pred.size(-1)),y_true.reshape(-1))\n",
    "        masked_loss = loss * mask\n",
    "        masked_loss_value = torch.sum(masked_loss)/torch.sum(mask.float())\n",
    "    \n",
    "        return masked_loss_value\n",
    "    def evaluate(self, elements):\n",
    "        official_A, official_B, official_C = 1e-10, 1e-10, 1e-10\n",
    "        \n",
    "        results = []\n",
    "\n",
    "        for batch in tqdm(iter(elements)):\n",
    "\n",
    "            R = self.model(batch['inputs'])\n",
    "            official_T = batch['targets']\n",
    "            \n",
    "            results.append({'text':tokenizer.decode(batch['inputs']), 'predict':list(R), 'truth':list(official_T)})\n",
    "            # R 与official_T都是集合内容\n",
    "            official_A += len(R & official_T)\n",
    "            official_B += len(R)\n",
    "            official_C += len(official_T)\n",
    "        \n",
    "        f1= 2* official_A/(official_B + official_C)\n",
    "        prec = official_A/official_B if official_B>1 else 0\n",
    "        recall = official_A/official_C\n",
    "        return f1,prec,recall, results\n",
    "    \n",
    "    def train_iteration(self, trainingargs):\n",
    "        # 对batch 进行一次前向传播\n",
    "        # 将batch 投入到模型中进行前向传播\n",
    "\n",
    "        global_steps=0\n",
    "        global_start_time = time.time()\n",
    "        dev_f1_history = []\n",
    "        \n",
    "        self.logger.log_train_start(Epochs=trainingargs['num_epochs'],lr=trainingargs['lr'])\n",
    "        \n",
    "        for epoch in tqdm(range(1,self.num_epochs+1)):\n",
    "            train_loss =0\n",
    "            \n",
    "            for batch in tqdm(self.trainloader):\n",
    "                start_time = time.time()\n",
    "                global_steps+=1\n",
    "                loss = self.train(batch)\n",
    "                train_loss += loss\n",
    "                if global_steps % trainingargs['log_steps'] == 0:\n",
    "                    duration = time.time() - start_time\n",
    "                    self.logger.log_epoch(epoch=epoch,loss= loss,num_epochs=self.num_epochs,duration=duration,lr=self.optimizer.param_groups[0]['lr'])\n",
    "                    \n",
    "                    wandb.log({\"Loss\":loss})\n",
    "                if self.trainingargs.get('clip_grad_norm'):\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(),self.trainingargs['clip_grad_norm'])\n",
    "                if global_steps % self.trainingargs['gradient_accumulation_steps']==0:\n",
    "                    \n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "                    self.model.zero_grad()\n",
    "                    \n",
    "                \n",
    "\n",
    "            # -------------------------\n",
    "            # 训练一个epoch 后\n",
    "            \n",
    "            self.logger.log_eval_start(len(self.valloader),epoch=epoch,num_epochs=self.num_epochs)\n",
    "            \n",
    "            dev_f1,dev_p,dev_r,results = self.evaluate(self.valloader, self.id2predicate, self.device)\n",
    "            # 平均训练损失\n",
    "            train_loss = train_loss /len(self.trainloader)\n",
    "            # 判断是否为最优的f1值\n",
    "            self.save_ckpt(epoch=epoch,performance_metric=dev_f1)\n",
    "            # model_file = model_save_dir + '/ckpt_epoch_'\n",
    "            if (epoch == 1 or dev_f1 >max(dev_f1_history) ) and trainingargs['predict']:\n",
    "                best_f1 = dev_f1\n",
    "                \n",
    "                if not os.path.exists(self.globalargs['model_save_dir'] +'/predict'):\n",
    "                    os.mkdir(self.globalargs['model_save_dir'] +'/predict')\n",
    "                with open(self.globalargs['model_save_dir'] +'/predict'+ '/best_dev_results.json', 'w') as fw:\n",
    "                    json.dump(results, fw, indent=4, ensure_ascii=False)\n",
    "            elif epoch == 1 or dev_f1 >max(dev_f1_history):\n",
    "                best_f1=dev_f1\n",
    "            else:\n",
    "                best_f1=max(dev_f1_history)       \n",
    "            self.logger.log_evaluation(phase='evaluation',recall = dev_r,accuracy=dev_p,f1=dev_f1,best_f1=best_f1)\n",
    "            dev_f1_history +=[dev_f1]\n",
    "            #增加梯度裁剪 与 梯度步数累计\n",
    "            self.scheduler.step()\n",
    "            wandb.log({\"Test Accu\":dev_p,\"Test F1\":dev_f1,\"Test Recall\":dev_r})\n",
    "        self.best_ckpt()\n",
    "        wandb.finish()\n",
    "        self.logger.log_train_end(self.num_epochs,best_f1,global_steps,duration=time.time()-global_start_time)\n",
    "            \n",
    "        pass\n",
    "    def test(self,args):\n",
    "            dev_f1,dev_p,dev_r,results = self.evaluate(self.valloader,self.tokenizer,self.id2predicate,self.device)\n",
    "            # 平均训练损失\n",
    "            # train_loss = train_loss /len(self.trainloader)\n",
    "            # 判断是否为最优的f1值\n",
    "            # self.save_ckpt(epoch=epoch,performance_metric=dev_f1)\n",
    "            # model_file = model_save_dir + '/ckpt_epoch_'\n",
    "            # if (epoch == 1 or dev_f1 >max(dev_f1_history) ) and args['predict']:\n",
    "            #     best_f1 = dev_f1\n",
    "            #     # copyfile(model_file, model_save_dir + '/best_model.pt')\n",
    "            if not os.path.exists(self.globalargs['model_save_dir'] +'/predict'):\n",
    "                os.mkdir(self.globalargs['model_save_dir'] +'/predict')\n",
    "            with open(self.globalargs['model_save_dir'] +'/predict'+ '/best_dev_results.json', 'w') as fw:\n",
    "                json.dump(results, fw, indent=4, ensure_ascii=False)\n",
    "            # elif epoch == 1 or dev_f1 >max(dev_f1_history):\n",
    "            #     best_f1=dev_f1\n",
    "            # else:\n",
    "            #     best_f1=max(dev_f1_history)       \n",
    "            self.logger.log_evaluation(phase='test',recall = dev_r,accuracy=dev_p,f1=dev_f1,best_f1=None)\n",
    "            \n",
    "\n",
    "    def train(self,batch):\n",
    "        inputs=batch[\"input_text\"].to(self.device)\n",
    "        \n",
    "        mask=batch['mask'].to(self.device)\n",
    "        memeoryinpus=batch['memory_input'].to(self.device)\n",
    "        Subjs_head=batch[\"subjs_head\"].to(self.device)\n",
    "        Subjs_tail=batch[\"subjs_tail\"].to(self.device)\n",
    "        Objs_head=batch[\"objs_head\"] .to(self.device)\n",
    "        Objs_tail=batch[\"objs_tail\"] .to(self.device)\n",
    "        subMask = batch[\"subMask\"].permute(1,0).to(self.device) # (subnums,batch)-->(batch,subnums)\n",
    "        self.model.train()\n",
    "        \n",
    "        \n",
    "        subj_head_logits, subj_tail_logits, obj_head_logits, obj_tail_logits = self.model(inputs=inputs, mask=mask,memory_inputs=memeoryinpus)\n",
    "        subj_head_loss = self.compute_loss(Subjs_head, subj_head_logits, mask)\n",
    "        subj_tail_loss = self.compute_loss(Subjs_tail, subj_tail_logits, mask)\n",
    "        obj_head_loss = self.compute_loss(Subjs_head, subj_head_logits, mask)\n",
    "        obj_tail_loss = self.compute_loss(Subjs_tail, subj_tail_logits, mask)\n",
    "        \n",
    "        loss=self.trainingargs['subj_loss_weight']*(subj_head_loss+subj_tail_loss)+self.trainingargs['type_loss_weight']*(obj_head_loss+obj_tail_loss)\n",
    "        loss.backward()\n",
    "        \n",
    "        loss_val = loss.data.item()\n",
    "        return loss_val\n",
    "    \n",
    "    def load_model(self,path):\n",
    "        try:\n",
    "            ckpt = torch.load(path)\n",
    "            self.logger.load_from_ckpt(path)\n",
    "        except:\n",
    "            print('Error! files can not load')\n",
    "            exit()\n",
    "        self.model.load_state_dict(ckpt['model'])\n",
    "        self.optimizer.load_state_dict = ckpt['optimizer_state_dict']\n",
    "        self.scheduler.load_state_dict = ckpt['scheduler_state_dict']\n",
    "        self.start_epoch = ckpt['epoch']+1\n",
    "    def save_model(self, filename, epoch):\n",
    "        params = {\n",
    "                'model': self.model.state_dict(),\n",
    "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "                'epoch': epoch\n",
    "                }\n",
    "        try:\n",
    "            torch.save(params, filename)\n",
    "            self.logger.load_to_ckpt(filename)\n",
    "        except BaseException:\n",
    "            print(\"[Warning: Saving failed... continuing anyway.]\")\n",
    "    def save_ckpt(self, epoch, performance_metric):\n",
    "        # 保存检查点\n",
    "        if not os.path.exists(self.globalargs['model_save_dir']+'/'+'ckpt'):\n",
    "            os.mkdir(self.globalargs['model_save_dir']+'/'+\"ckpt\")\n",
    "        \n",
    "        checkpoint_path = self.globalargs['model_save_dir'] +\"/\"+'ckpt'+'/'+f\"checkpoint_{epoch}.pth\"\n",
    "        # ...保存模型状态、优化器状态等信息到checkpoint_path\n",
    "        \n",
    "        # 存储性能指标和检查点路径到字典中\n",
    "        self.checkpoints[checkpoint_path] = performance_metric\n",
    "\n",
    "        # 如果保存的检查点数量超过限制，则删除性能最差的检查点\n",
    "        if len(self.checkpoints) > self.total_save_limit:\n",
    "            # 找到性能最差的检查点\n",
    "            # worst_checkpoint = min(self.checkpoints, key=lambda x:(self.checkpoints[x].get,self.checkpoints[x].split('.')[0].split('_')[-1]))\n",
    "            worst_checkpoints = sorted(self.checkpoints.items(), key=lambda x:x[1])\n",
    "            print(worst_checkpoints)\n",
    "            # print(worst_checkpoint)\n",
    "            worst_checkpoint = worst_checkpoints[0][0]\n",
    "            for i in range(1,len(worst_checkpoints)):\n",
    "                if self.checkpoints[worst_checkpoints[i][0]]>self.checkpoints[worst_checkpoint]:\n",
    "                    break\n",
    "                else:\n",
    "                    if worst_checkpoint.split('_')[-1].split('.')[0] >worst_checkpoints[i][0].split('_')[-1].split('.')[0]:\n",
    "                        worst_checkpoint=worst_checkpoints[i][0]\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "            if os.path.exists(worst_checkpoint):\n",
    "                os.remove(worst_checkpoint)\n",
    "                # print(os.listdir('/'.join(worst_checkpoint.split('/')[:-1])))\n",
    "                del self.checkpoints[worst_checkpoint]  # 从字典中删除最差的检查点\n",
    "                self.save_model(checkpoint_path,epoch=epoch)\n",
    "            else:\n",
    "                del self.checkpoints[worst_checkpoint]\n",
    "        else:\n",
    "            self.save_model(checkpoint_path,epoch=epoch)\n",
    "    def best_ckpt(self):\n",
    "        best_checkpoint = max(self.checkpoints, key=self.checkpoints.get)\n",
    "        copyfile(best_checkpoint, self.globalargs['model_save_dir'] + '/best_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import wandb\n",
    "def workflow(batch_size,data_path,val_size,tokenizer, task_name):\n",
    "    all_dataset = load_from_disk('/home/RE/Dataset/pretrained_ds')\n",
    "    \n",
    "    traindataset,valdataset = all_dataset,None if val_size <0.0001 else random_split(all_dataset,[len(all_dataset)-int(len(all_dataset)*val_size),int(len(all_dataset)*val_size)])\n",
    "    my_data_collator = partial(pad_sequence, pad_id = tokenizer.pad_token_id)\n",
    "\n",
    "    trainloader = DataLoader(traindataset, batch_size= batch_size, shuffle = True, collate_fn = my_data_collator)\n",
    "    if valdataset is not None:\n",
    "        valloader = DataLoader(valdataset, batch_size = batch_size, shuffle = True, collate_fn = my_data_collator)\n",
    "    wandb.init(project=task_name, name=\"wandb\"+f\"size_{val_size}_batch{batch_size}\")\n",
    "    wandb.watch(model)\n",
    "    trainer = ReTrainer(\n",
    "        trainloader = trainloader,\n",
    "        valloader=valloader,\n",
    "        model = model,\n",
    "        tokenizer = tokenizer,\n",
    "        \n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparams\n",
    "1. data_path\n",
    "2. model_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "class Seq2SeqDataset(Dataset):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score test bench"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cypy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
